{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c369d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.path.abspath(\"../src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f209b4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varshakumar/Documents/iMutoInternship/hello-fastapi-poetry/.venv/lib/python3.11/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'orm_mode' has been renamed to 'from_attributes'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "from hello_api.api_client import APIClient\n",
    "import asyncio\n",
    "import ollama \n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a helpful assistant helping a student prepare for a test. \"\n",
    "    \"Take the following information and write detailed, accurate study notes.\"\n",
    ")\n",
    "\n",
    "async def generate_notes(subject: str) -> str:\n",
    "    summary = wikipedia.summary(subject, sentences=3)\n",
    "\n",
    "    response = await ollama.chat(\n",
    "        model=\"llama3\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"Make detailed notes for: {subject}\\n\\n{summary}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d562eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hello_api.notes.schema import NoteCreateUpdate\n",
    "\n",
    "async def save_notes_to_db(subject: str, notes: str):\n",
    "    client = APIClient()\n",
    "    note = NoteCreateUpdate(title=subject, content=notes)\n",
    "    await client.upsert_note(note)\n",
    "    await client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee29967",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PROMPT = (\n",
    "    \"You are a test creator. Based on the following study notes, generate 10 DIFFICULT, factual, recall-based test questions. \"\n",
    "    \"Only return the list of questions as strings.\"\n",
    ")\n",
    "\n",
    "async def generate_test_questions(notes: str) -> list[str]:\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": QUESTION_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"Generate questions based on:\\n\\n{notes}\"}\n",
    "        ]\n",
    "    )\n",
    "    questions = response[\"message\"][\"content\"].strip().split(\"\\n\")\n",
    "    return [q.strip(\"- \").strip() for q in questions if q.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff70f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def save_test_to_yaml(test_dict: dict, file_path=\"testset.yaml\"):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        yaml.dump(test_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f9144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_full_pipeline(subjects: list[str]):\n",
    "    test_results = {}\n",
    "    for subject in subjects:\n",
    "        print(f\"Processing: {subject}\")\n",
    "        notes = await generate_notes(subject)\n",
    "        await save_notes_to_db(subject, notes)\n",
    "        questions = await generate_test_questions(notes)\n",
    "        test_results[subject] = questions\n",
    "\n",
    "    save_test_to_yaml(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c493092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Voyager Program\n"
     ]
    }
   ],
   "source": [
    "subjects = [\n",
    "    \"Voyager Program\", \"Chernobyl Disaster\", \"Periodic Table\",\n",
    "    \"Human Genome Project\", \"French Revolution\", \"Apollo 11\",\n",
    "    \"Great Barrier Reef\", \"Watergate Scandal\", \"CRISPR Gene Editing\"\n",
    "]\n",
    "\n",
    "await run_full_pipeline(subjects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
